{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1256ea85",
   "metadata": {},
   "source": [
    "# Downloading PotentialNet Model and host it locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c92339",
   "metadata": {},
   "source": [
    "This notebook shows how to use a potential net model trained on SageMaker.\n",
    "First, please download the model.tar.gz file created by the SageMaker training job to this directory. Then, untar the model file using the command below. You will see 3 files: best_test_model.pth, best_val_model.pth and model.pth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31220615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee828ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -zxvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad24c0",
   "metadata": {},
   "source": [
    "Please set your data_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6796fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'graph_files_v2020_core_13_withPDBID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f2852",
   "metadata": {},
   "source": [
    "Then, create a custom dataset/dataloader object as we did on the SageMaker training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append('code/')\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, lst_graph1_paths):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.len = len(lst_graph1_paths)\n",
    "        self.lst = lst_graph1_paths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        graphs1, label_dict = load_graphs(self.lst[index])\n",
    "        graphs2, label_dict = load_graphs(self.lst[index].replace('_g1.bin', '_g2.bin'))\n",
    "        label = label_dict['glabel']\n",
    "        \n",
    "        graphs1_batch = [dgl.batch([graphs1[i],graphs1[i+1]]) for i in range(0, int(len(graphs1)), 2)]\n",
    "        bg = [tuple([graphs1_batch[i],graphs2[i]]) for i in range(0, int(len(graphs2)), 1)]\n",
    "        \n",
    "        return bg[0], label\n",
    "    \n",
    "def collate(data):\n",
    "    graphs, labels = map(list, zip(*data))\n",
    "    if (type(graphs[0]) == tuple):\n",
    "        bg1 = dgl.batch([g[0] for g in graphs])\n",
    "        bg2 = dgl.batch([g[1] for g in graphs])\n",
    "        bg = (bg1, bg2) # return a tuple for PotentialNet\n",
    "    else:\n",
    "        bg = dgl.batch(graphs)\n",
    "        for nty in bg.ntypes:\n",
    "            bg.set_n_initializer(dgl.init.zero_initializer, ntype=nty)\n",
    "        for ety in bg.canonical_etypes:\n",
    "            bg.set_e_initializer(dgl.init.zero_initializer, etype=ety)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    return bg, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a453424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dgl.data.utils import load_graphs\n",
    "import dgl\n",
    "\n",
    "lst_g1 = glob.glob(data_dir +\"/\"+ \"**_g1.bin\")\n",
    "inf_data_set = MyDataset(lst_g1)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "        dataset=inf_data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate,\n",
    "        pin_memory=True,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d7ff0",
   "metadata": {},
   "source": [
    "We recreate a potential net model with the same configuration, and load weights of trained model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.model import ACNN, PotentialNet\n",
    "from configure import get_exp_configure\n",
    "from utils import load_dataset, load_model, rand_hyperparams, set_random_seed\n",
    "import torch\n",
    "\n",
    "args = {}\n",
    "args[\"model\"] = \"PotentialNet\"\n",
    "args[\"dataset_option\"] = \"PDBBind_refined_pocket_scaffold\"\n",
    "args[\"exp\"] = \"_\".join([args[\"model\"], args[\"dataset_option\"]])\n",
    "\n",
    "default_exp = get_exp_configure(args[\"exp\"])\n",
    "for i in default_exp.keys():\n",
    "    args.setdefault(i, default_exp[i])\n",
    "args['distance_bins'] =  [1.5, 2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 4.5]\n",
    "\n",
    "model = PotentialNet(n_etypes=(len(args['distance_bins'])+ 5),\n",
    "                             f_in=args['f_in'],\n",
    "                             f_bond=args['f_bond'],\n",
    "                             f_spatial=args['f_spatial'],\n",
    "                             f_gather=args['f_gather'],\n",
    "                             n_rows_fc=args['n_rows_fc'],\n",
    "                             n_bond_conv_steps=args['n_bond_conv_steps'],\n",
    "                             n_spatial_conv_steps=args['n_spatial_conv_steps'],\n",
    "                             dropouts=args['dropouts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797305de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_test_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d202ac4",
   "metadata": {},
   "source": [
    "Finally, predict with test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a837e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_id, batch_data in enumerate(data_loader):\n",
    "        bg, labels = batch_data\n",
    "        labels = labels\n",
    "        bigraph_canonical, knn_graph = bg  # unpack stage1_graph, stage2_graph\n",
    "        bigraph_canonical = bigraph_canonical\n",
    "        knn_graph = knn_graph\n",
    "        prediction = model(bigraph_canonical, knn_graph)\n",
    "        print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08d158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
